[["index.html", "21,578 Reuters’ Newswires 1 Prepare Data", " 21,578 Reuters’ Newswires Shaina Race Bennett, PhD 1 Prepare Data -1. Get datetimes from python script. 0. Copy text of raw documents to separate vector for visualization/results. 1. Make lower case, emove stop words + “Reuters”, punctuation, and numbers; No stemming was ultimately used. 3. Create binary term-document matrix to remove terms occurring in less than 5 documents. 5. Remove documents left with fewer than 10 words remaining. 6. Ready the datetime, topics, and heading information for visualization. #setwd(&#39;/Users/shaina/Library/Mobile Documents/com~apple~CloudDocs/Datasets and Code/reuters21578/&#39;) # load(&#39;Reuters.RData&#39;) # # Step 0 # # 1 # ############################################################ # R = Reuters21578 # R = tm_map(R,content_transformer(tolower)) # ############################################################ # # 2 # ############################################################ # R = tm_map(R,removeWords,stopwords(&quot;en&quot;)) # R = tm_map(R,removePunctuation) # R = tm_map(R,removeNumbers) # #R = tm_map(R,stemDocument) # R = tm_map(R,removeWords, c(&#39;reuters&#39;)) # ############################################################ # # 3 # ############################################################ # tdm = TermDocumentMatrix(R) # binary = weightBin(tdm) # ############################################################ # # 4 # ############################################################ # keep_terms = row_sums(binary)&gt;=5 # tdm = tdm[keep_terms,] # ############################################################ # # 5 # ############################################################ # keep_docs = col_sums(tdm)&gt;10 # R = R[keep_docs] # tdm = tdm[,keep_docs ] # dim(tdm) # length(R) # ############################################################ # datetime = read.csv(&#39;datetimes.csv&#39;) # datetime=datetime[keep_docs,] # head = unlist(meta(R,&quot;heading&quot;)) # ############################################################ # raw_data = unlist(content(Reuters21578[keep_docs])) # raw_text=raw_data[names(raw_data)==&#39;content&#39;] # raw_text = str_squish(raw_text) # head=raw_data[names(raw_data)==&#39;meta.heading&#39;] # head = str_squish(head) # lewissplit = raw_data[names(raw_data)==&#39;meta.lewissplit&#39;] # ############################################################ # # add breaks for text wrapping # ############################################################ # # raw_text = gsub(&quot;(.{60,}?)\\\\s&quot;, &quot;\\\\1&lt;br&gt;&quot;, raw_text) ############################################################ # Save data to avoid repeat processing ############################################################ # save(raw_text,head,lewissplit,tdm,R,datetime, file=&#39;processedV1.RData&#39;) load(&#39;processedV1.RData&#39;) "],["exploratory-analysis-via-svd.html", "2 Exploratory Analysis via SVD", " 2 Exploratory Analysis via SVD # tfidf_tdm = weightTfIdf(tdm, normalize=T) # m = Matrix::sparseMatrix(i=tfidf_tdm$i, # j=tfidf_tdm$j, # x=tfidf_tdm$v, # dims=c(tfidf_tdm$nrow, tfidf_tdm$ncol), # dimnames = tfidf_tdm$dimnames) #svd = irlba(m, 150) #save(svd,file=&#39;svd.RData&#39;) load(&#39;svd.RData&#39;) df = data.frame(x=1:150,d=svd$d) g1 = ggplot(data=df, aes(x=x, y=d, group=1)) + geom_line(color=&quot;red&quot;)+labs(y=&#39;Singular Values&#39;,x=&#39;index&#39;, title=&#39;Screeplot of Reuters tf-idf Matrix, vlines at 10, 25&#39;) + geom_point() + geom_vline(xintercept = 25, linetype=&quot;dotted&quot;, color = &quot;blue&quot;, size=1) + geom_vline(xintercept = 10, linetype=&quot;dotted&quot;, color = &quot;blue&quot;, size=1) u.df = data.frame(x=svd$v[,1], y=svd$v[,2]) g2 = ggplot(data=u.df, aes(x=x, y=y)) + geom_point()+labs(y=&#39;Second Singular Component&#39;,x=&#39;First Singular Component&#39;, title=&#39;SVD Projection of Reuters tf-idf Term-Document Matrix&#39;) grid.arrange(g1,g2,ncol=1) "],["umap.html", "3 UMAP", " 3 UMAP We’ll use the mathemagical Uniform Manifold Approximation and Projection (UMAP) algorithm to project the already dimension-reduced data (150 singular vectors) into 2-space. # svd_ump = umap(svd$v) # save(svd_ump, file=&#39;svd_ump.RData&#39;) load(&#39;svd_ump.RData&#39;) fig &lt;- plot_ly(type = &#39;scatter&#39;, mode = &#39;markers&#39;) fig &lt;- fig %&gt;% add_trace( x = svd_ump$layout[,1], y = svd_ump$layout[,2], text = ~paste(&#39;heading:&#39;, head ,&quot;$&lt;br&gt;text: &quot;, raw_text ), hoverinfo = &#39;text&#39;, marker = list(color=&#39;green&#39;), showlegend = F ) fig Outliers causing annoying viz issues requiring the zoom. We will routinely omit these outliers (after noting they make nice clusters of related documents) when creating the plot to avoid having to zoom on the main plot. index_subset = abs(svd_ump$layout[,1]) &lt;20 &amp; abs(svd_ump$layout[,2]) &lt;20 data_subset = svd_ump$layout[index_subset,] raw_text_subset = raw_text[index_subset] head_subset = head[index_subset] fig &lt;- plot_ly(type = &#39;scatter&#39;, mode = &#39;markers&#39;) fig &lt;- fig %&gt;% add_trace( x = data_subset[,1], y = data_subset[,2], text = ~paste(&#39;heading:&#39;, head_subset ,&quot;$&lt;br&gt;text: &quot;, raw_text_subset ), hoverinfo = &#39;text&#39;, marker = list(color=&#39;green&#39;), showlegend = F ) fig After omitting the outliers, we see a nice plot that looks like it has some nice cluster separation. "],["clustering-hdbscan.html", "4 Clustering: HDBSCAN 4.1 Prepare top words, Cluster documents", " 4 Clustering: HDBSCAN Two options here - can cluster this UMAP projection or can opt to cluster some higher-dimensional projection (like the singular vectors themselves) and see how that looks in the UMAP Space. UMAP clustering seems to perform really well, even better than singular vector input, so we stick with it. We define n as the number of documents and k as the number of clusters. Hierarchical DBSCAN is a fast algorithm that adapts the ideas of single linkage clustering (minimal spanning trees) to DBSCAN (density based spatial clustering of applications with noise) to create a hierarchical map of density based clusters. ### clus = hdbscan(svd$v[,1:25],10) ### save(clus,file=&#39;hdbscan_clusters10.RData&#39;) ### load(&#39;hdbscan_clusters10.RData&#39;) #clus = hdbscan(svd_ump$layout,5) # save(clus,file=&#39;alldocs_hdbscan_of_map5.RData&#39;) load(&#39;alldocs_hdbscan_of_map5.RData&#39;) n=length(clus$cluster) (k = length(clus$cluster_scores)) ## [1] 733 We get a LOT of clusters from hdbscan - this makes sense, there is a lot going on in this corpus! But it might be nice to refine those clusters so that we can see which ones are related. We’ll get to that after we explore this great visualization. 4.1 Prepare top words, Cluster documents Get top words for further visualization and pile all documents in a cluster into one giant document for the purposes of summarization. top.words=list() cluster.docs = vector() centroids = matrix(NA,k,2) mem=matrix(NA,nrow=n,ncol=k) for(i in 1:k){ mem[,i] = clus$cluster ==i tdmi = tdm[,mem[,i]] rs = row_sums(tdmi) top.words[[i]] = names(rs[order(rs,decreasing=T)])[1:10] cluster.docs[i] = paste(raw_text_subset[clus$cluster ==i], sep=&#39;&#39;, collapse=&#39; &#39;) centroids[i,]=colMeans(svd_ump$layout[clus$cluster ==i,]) } displayWords=vector() for(i in 1:k){displayWords[i] = paste(top.words[[i]][1:7] , sep=&#39; &#39;, collapse=&#39;&lt;br&gt;&#39;)} "],["the-grand-visualization.html", "5 The Grand Visualization 5.1 Omit some noise points for more cluster clarity", " 5 The Grand Visualization Full Page Rendering Note: We don’t have enough colors! The colors are recycled but hopefully will still help. Cluster numbers in tooltip for certainty clusters = factor(clus$cluster[index_subset]) fig &lt;- plot_ly(type = &#39;scatter&#39;, mode = &#39;markers&#39;) fig &lt;- fig %&gt;% add_trace( x = data_subset[,1], y = data_subset[,2], text = ~paste(&#39;Heading:&#39;, head_subset ,&quot;$&lt;br&gt;Text: &quot;, raw_text_subset ,&quot;$&lt;br&gt;Cluster Number: &quot;, clusters), hoverinfo = &#39;text&#39;, color = clusters, showlegend = F ) fig ## Warning in RColorBrewer::brewer.pal(N, &quot;Set2&quot;): n too large, allowed maximum for palette Set2 is 8 ## Returning the palette you asked for with that many colors ## Warning in RColorBrewer::brewer.pal(N, &quot;Set2&quot;): n too large, allowed maximum for palette Set2 is 8 ## Returning the palette you asked for with that many colors #saveWidget(fig, &quot;All_clusters_noTopics_UMAPClus_wNoise.html&quot;) 5.1 Omit some noise points for more cluster clarity We could reduce the noise on the plot by omitting some of the points with high outlier scores, but generally I hate doing this because it can be a good way to accidently lose something you didn’t know you wanted. However, it could have it’s advantages as a strategy and the outlier_score of hdbscan() is a nice threshold to play with for further analytical paths. Full Page Rendering index_subset = abs(svd_ump$layout[,1]) &lt;20 &amp; abs(svd_ump$layout[,2]) &lt;20 &amp; clus$outlier_scores&lt;0.6 data_subset = svd_ump$layout[index_subset,] raw_text_subset = raw_text[index_subset] head_subset = head[index_subset] clusters = factor(clus$cluster[index_subset]) fig &lt;- plot_ly(type = &#39;scatter&#39;, mode = &#39;markers&#39;) fig &lt;- fig %&gt;% add_trace( x = data_subset[,1], y = data_subset[,2], text = ~paste(&#39;Heading:&#39;, head_subset ,&quot;$&lt;br&gt;Text: &quot;, raw_text_subset ,&quot;$&lt;br&gt;Cluster Number: &quot;, clusters), hoverinfo = &#39;text&#39;, color = clusters, showlegend = F ) fig ## Warning in RColorBrewer::brewer.pal(N, &quot;Set2&quot;): n too large, allowed maximum for palette Set2 is 8 ## Returning the palette you asked for with that many colors ## Warning in RColorBrewer::brewer.pal(N, &quot;Set2&quot;): n too large, allowed maximum for palette Set2 is 8 ## Returning the palette you asked for with that many colors #saveWidget(fig, &quot;All_clusters_noTopics_UMAPClus.html&quot;) "],["cluster-refinement.html", "6 Cluster Refinement 6.1 Refinement Idea 1: Clustering the centroids 6.2 Refinement Idea 1: Divide and Conquer", " 6 Cluster Refinement Problem: Many medium-big clusters get broken up even though they seem nicely separated on the UMAP projection. Would love to deal with the big center blob a bit better. Two ideas for potential refinement: Run the clustering again on centroids of clusters Focus on the blob and see if treating it separately helps - potentially less information overall to squeeze into the viz, allowing for more separation - divide and conquer. The first idea is easier so we’ll start there: 6.1 Refinement Idea 1: Clustering the centroids cen_clus = hdbscan(centroids, 3) # Down to 78 Clusters...Looks Pretty Good. # Omit the 2 outside fig &lt;- plot_ly(type = &#39;scatter&#39;, mode = &#39;markers&#39;)%&gt;% add_trace(x = centroids[,1], y = centroids[,2], text = ~paste(&#39;Key Words:&#39;, displayWords,&quot;$&lt;br&gt;Cluster Number: &quot;, cen_clus$cluster ), color=factor(cen_clus$cluster), showlegend = FALSE) fig ## Warning in RColorBrewer::brewer.pal(N, &quot;Set2&quot;): n too large, allowed maximum for palette Set2 is 8 ## Returning the palette you asked for with that many colors ## Warning in RColorBrewer::brewer.pal(N, &quot;Set2&quot;): n too large, allowed maximum for palette Set2 is 8 ## Returning the palette you asked for with that many colors Now we just need a function that maps the new centroid clustering back to the original points. Essentially one line of code in R, thanks to subsetting functionality (final line of function remapClusters below) but with the minor problem that noise points create an extra cluster. We simply add the noise cluster to the vector as cluster number k+1, and give it a value of 0 similar to the noise points. Additional thought (not implemented) leave the noise points IN and cluster them with the centroids. This is a good idea because it allows points that were previously labeled as noise to potentially join a cluster of nearby centroids. remapClusters = function(cen_clus,clus){ k = length(clus$cluster_scores) c=as.vector(clus$cluster) c[c==0]=k+1 cc=as.vector(cen_clus$cluster) cc[k+1]=0 new = cc[c] return(new) } Grand Visualization of Refined Clusters Full Page Rendering newclusters = remapClusters(cen_clus, clus) newclusters = newclusters[index_subset] fig &lt;- plot_ly(type = &#39;scatter&#39;, mode = &#39;markers&#39;) fig &lt;- fig %&gt;% add_trace( x = data_subset[,1], y = data_subset[,2], text = ~paste(&#39;Heading:&#39;, head_subset ,&quot;$&lt;br&gt;Text: &quot;, raw_text_subset ,&quot;$&lt;br&gt;Cluster Number: &quot;, clusters), hoverinfo = &#39;text&#39;, color = factor(newclusters), showlegend = F ) fig ## Warning in RColorBrewer::brewer.pal(N, &quot;Set2&quot;): n too large, allowed maximum for palette Set2 is 8 ## Returning the palette you asked for with that many colors ## Warning in RColorBrewer::brewer.pal(N, &quot;Set2&quot;): n too large, allowed maximum for palette Set2 is 8 ## Returning the palette you asked for with that many colors #saveWidget(fig, &quot;All_centroid_refined_clusters.html&quot;) Onto the next thought for refinement: divide and conquer. 6.2 Refinement Idea 1: Divide and Conquer Here, we divide the data according to UMAP and recompute the SVD of that subset. We see better cluster separation than we did in the corresponding rectangle on our original “Grand Viz”, which suggests this might be a viable line of attack. Full Page Rendering # Take rectangular subset on the interval x=y=[-2,2] index_subset2=abs(svd_ump$layout[,1]) &lt;2 &amp; abs(svd_ump$layout[,2]) &lt;2 tdm_subset = tdm[,index_subset2] tdm_subset = tdm_subset[row_sums(tdm_subset)!=0, ] tfidf_tdm_subset = weightTfIdf(tdm_subset, normalize=T) m = Matrix::sparseMatrix(i=tfidf_tdm_subset$i, j=tfidf_tdm_subset$j, x=tfidf_tdm_subset$v, dims=c(tfidf_tdm_subset$nrow, tfidf_tdm_subset$ncol), dimnames = tfidf_tdm_subset$dimnames) # Take SVD of the subset and compute the UMAP svd_subset = irlba(m,15) svd_subset_map = umap(svd_subset$v) # Subset raw text for visualization raw_text_subset2 = raw_text[index_subset2] head_subset2 = head[index_subset2] # Cluster clus2=hdbscan(svd_subset_map$layout,4) fig2 &lt;- plot_ly(type = &#39;scatter&#39;, mode = &#39;markers&#39;) fig2 &lt;- fig2 %&gt;% add_trace( x = svd_subset_map$layout[,1], y = svd_subset_map$layout[,2], text = ~paste(&#39;heading:&#39;, head_subset2 ,&quot;$&lt;br&gt;text: &quot;, raw_text_subset2,&quot;$&lt;br&gt;Cluster Number: &quot;, clus2$cluster ), hoverinfo = &#39;text&#39;, color=factor(clus2$cluster), showlegend = F ) fig2 ## Warning in RColorBrewer::brewer.pal(N, &quot;Set2&quot;): n too large, allowed maximum for palette Set2 is 8 ## Returning the palette you asked for with that many colors ## Warning in RColorBrewer::brewer.pal(N, &quot;Set2&quot;): n too large, allowed maximum for palette Set2 is 8 ## Returning the palette you asked for with that many colors #saveWidget(fig2, &#39;Plots/SubsettingUMAPforRepeatSVD.html&#39;) "]]
